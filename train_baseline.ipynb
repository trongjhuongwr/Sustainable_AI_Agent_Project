{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca2e9dfd",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# BASELINE MODEL TRAINING NOTEBOOK\n",
    "# =============================================================================\n",
    "## Purpose:\n",
    "    - Load and preprocess the raw weather dataset.\n",
    "    - Define the Gated Recurrent Unit (GRU) model architecture.\n",
    "    - Train the baseline GRU model using specified hyperparameters and save its state.\n",
    "    - Save the preprocessed and split data tensors for subsequent use.\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c466dd",
   "metadata": {},
   "source": [
    "# === Clone Repository & Install Dependencies ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc50b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf Sustainable_AI_Agent_Project\n",
    "!git clone https://github.com/trongjhuongwr/Sustainable_AI_Agent_Project.git\n",
    "%cd Sustainable_AI_Agent_Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0597566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --extra-index-url https://download.pytorch.org/whl/cu121 -r /kaggle/working/Sustainable_AI_Agent_Project/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8157345e",
   "metadata": {},
   "source": [
    "# 1. Import Libraries and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601be0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "os.environ[\"GYM_DISABLE_WARNINGS\"] = \"true\"\n",
    "warnings.filterwarnings(\"ignore\", module=\"gymnasium\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "logging.getLogger(\"gymnasium\").setLevel(logging.ERROR)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from builtins import print as builtin_print\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8df516",
   "metadata": {},
   "source": [
    "# 2. Configuration Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aa21b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines hyperparameters, file paths, and other parameters used throughout the baseline training process.\n",
    "class Config:\n",
    "    # --- Data Paths ---\n",
    "    DATA_PATH = '/kaggle/input/seattle-weather/seattle-weather.csv' # Path to the raw dataset CSV file\n",
    "    PROCESSED_DATA_SAVE_PATH = '/kaggle/working/processed_data.pt' # Output path for saving processed data tensors\n",
    "    BASELINE_MODEL_SAVE_PATH = '/kaggle/working/baseline_model.pth' # Output path for saving the trained baseline model state dictionary\n",
    "\n",
    "    # --- Data Preprocessing Parameters ---\n",
    "    SEQUENCE_LENGTH = 30 # Number of past days used to predict the next day\n",
    "    TEST_SIZE = 0.2 # Proportion of data reserved for the final test set\n",
    "    VAL_SIZE_FROM_TEMP = 0.1 # Proportion of the remaining data (after test split) used for validation\n",
    "    SEED = 42 # Random seed for reproducibility\n",
    "\n",
    "    # --- Model Architecture Parameters ---\n",
    "    INPUT_DIM = 4      # Number of input features: precipitation, temp_max, temp_min, wind\n",
    "    HIDDEN_DIM = 256   # Dimensionality of the GRU hidden state\n",
    "    N_LAYERS = 2       # Number of stacked GRU layers\n",
    "    OUTPUT_DIM = 1     # Output dimension (binary classification: rain probability)\n",
    "    DROPOUT = 0.2      # Dropout rate applied between GRU layers\n",
    "\n",
    "    # --- Training Hyperparameters ---\n",
    "    BATCH_SIZE = 64\n",
    "    EPOCHS = 500       # Number of training epochs\n",
    "    LEARNING_RATE = 0.0001\n",
    "    WEIGHT_DECAY = 1e-4 # Weight decay for AdamW optimizer\n",
    "    SCHEDULER_T_MAX = 50  # T_max for CosineAnnealingLR scheduler (cycle length)\n",
    "    SCHEDULER_ETA_MIN = 1e-6 # Minimum learning rate for scheduler\n",
    "\n",
    "    # --- Computation Device ---\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(Config.SEED)\n",
    "np.random.seed(Config.SEED)\n",
    "torch.manual_seed(Config.SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(Config.SEED)\n",
    "    torch.cuda.manual_seed_all(Config.SEED)\n",
    "    # Optional: Enable deterministic algorithms for full reproducibility, may impact performance\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "    # torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"Configuration loaded. Using device: {Config.DEVICE}\")\n",
    "print(f\"Seed set to: {Config.SEED}\")\n",
    "print(f\"Processed data will be saved to: {Config.PROCESSED_DATA_SAVE_PATH}\")\n",
    "print(f\"Baseline model will be saved to: {Config.BASELINE_MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a161f270",
   "metadata": {},
   "source": [
    "# 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d428fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the dataset, performs feature engineering, scales features, creates time sequences,\n",
    "# splits data into training, validation, and test sets, and converts them to PyTorch tensors.\n",
    "\n",
    "def create_sequences(input_data, target_data, sequence_length):\n",
    "    \"\"\"\n",
    "    Generates sequences suitable for time-series forecasting with RNNs.\n",
    "    Args:\n",
    "        input_data (np.ndarray): Array of input features.\n",
    "        target_data (np.ndarray): Array of target values.\n",
    "        sequence_length (int): The length of each input sequence.\n",
    "    Returns:\n",
    "        tuple: (np.ndarray, np.ndarray) containing input sequences and corresponding targets.\n",
    "    \"\"\"\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(input_data) - sequence_length):\n",
    "        x = input_data[i:(i + sequence_length)]\n",
    "        y = target_data[i + sequence_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv(Config.DATA_PATH)\n",
    "    builtin_print(f\"Dataset loaded successfully from {Config.DATA_PATH}. Shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    builtin_print(f\"Error: Dataset file not found at {Config.DATA_PATH}. Please ensure the dataset is correctly added.\")\n",
    "    raise\n",
    "\n",
    "# Feature Engineering: Convert categorical weather to binary target\n",
    "df['weather_numeric'] = df['weather'].apply(lambda x: 1 if x in ['rain', 'drizzle'] else 0)\n",
    "df = df.drop(columns=['date', 'weather']) # Drop original date and weather columns\n",
    "\n",
    "# Scaling: Normalize input features to [0, 1] range\n",
    "scaler = MinMaxScaler()\n",
    "features_to_scale = ['precipitation', 'temp_max', 'temp_min', 'wind'] # Explicitly list features\n",
    "scaled_features_np = scaler.fit_transform(df[features_to_scale])\n",
    "target_np = df['weather_numeric'].values\n",
    "builtin_print(\"Input features scaled using MinMaxScaler.\")\n",
    "\n",
    "# Sequence Creation: Generate input sequences and corresponding targets\n",
    "X_np, y_np = create_sequences(scaled_features_np, target_np, Config.SEQUENCE_LENGTH)\n",
    "builtin_print(f\"Sequences created with length {Config.SEQUENCE_LENGTH}. Shape X: {X_np.shape}, Shape y: {y_np.shape}\")\n",
    "\n",
    "# Data Splitting: Stratified split into train, validation, and test sets\n",
    "# First split: Separate the test set (20%)\n",
    "X_temp, X_test_np, y_temp, y_test_np = train_test_split(\n",
    "    X_np, y_np,\n",
    "    test_size=Config.TEST_SIZE,\n",
    "    random_state=Config.SEED,\n",
    "    stratify=y_np # Ensure proportional target distribution\n",
    ")\n",
    "# Second split: Split the remaining data into train (90% of remainder) and validation (10% of remainder)\n",
    "X_train_np, X_val_np, y_train_np, y_val_np = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=Config.VAL_SIZE_FROM_TEMP,\n",
    "    random_state=Config.SEED,\n",
    "    stratify=y_temp # Ensure proportional target distribution\n",
    ")\n",
    "builtin_print(f\"Data split completed: Train={len(X_train_np)}, Validation={len(X_val_np)}, Test={len(X_test_np)}\")\n",
    "\n",
    "# Convert NumPy arrays to PyTorch Tensors\n",
    "X_train_tensor = torch.tensor(X_train_np, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_np, dtype=torch.float32).unsqueeze(1) # Add channel dim for BCELoss\n",
    "X_val_tensor = torch.tensor(X_val_np, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val_np, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_np, dtype=torch.float32).unsqueeze(1)\n",
    "builtin_print(\"Data successfully converted to PyTorch tensors.\")\n",
    "\n",
    "# Save the processed data tensors for use by other notebooks\n",
    "processed_data = {\n",
    "    'X_train': X_train_tensor, 'y_train': y_train_tensor,\n",
    "    'X_val': X_val_tensor, 'y_val': y_val_tensor,\n",
    "    'X_test': X_test_tensor, 'y_test': y_test_tensor,\n",
    "}\n",
    "try:\n",
    "    torch.save(processed_data, Config.PROCESSED_DATA_SAVE_PATH)\n",
    "    builtin_print(f\"Processed data tensors saved to {Config.PROCESSED_DATA_SAVE_PATH}\")\n",
    "except Exception as e:\n",
    "    builtin_print(f\"Error saving processed data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440be821",
   "metadata": {},
   "source": [
    "# 4. GRU Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9695c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the architecture of the Gated Recurrent Unit network used for weather prediction.\n",
    "\n",
    "class WeatherGRU(nn.Module):\n",
    "    \"\"\"\n",
    "    GRU model for binary weather prediction based on past sequence data.\n",
    "    Args:\n",
    "        input_dim (int): Number of input features.\n",
    "        hidden_dim (int): Dimension of the GRU hidden state.\n",
    "        n_layers (int): Number of stacked GRU layers.\n",
    "        output_dim (int): Number of output units (1 for binary classification).\n",
    "        dropout (float): Dropout probability applied between GRU layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, n_layers, output_dim, dropout):\n",
    "        super(WeatherGRU, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # GRU Layer: batch_first=True expects input shape (batch, seq_len, features)\n",
    "        # Dropout is applied only between layers if n_layers > 1\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers,\n",
    "                          batch_first=True, dropout=dropout if n_layers > 1 else 0)\n",
    "\n",
    "        # Fully Connected Layer: Maps the last hidden state to the output dimension\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        # Sigmoid Activation: Outputs a probability for binary classification\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the GRU network.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch, sequence_length, input_dim).\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of shape (batch, output_dim) representing probabilities.\n",
    "        \"\"\"\n",
    "        # GRU layer processes the sequence\n",
    "        # We don't explicitly need the final hidden state `h_n` here\n",
    "        gru_out, _ = self.gru(x)\n",
    "\n",
    "        # Select the output from the last time step of the sequence\n",
    "        # gru_out shape: (batch, seq_len, hidden_dim) -> gru_out[:, -1, :] shape: (batch, hidden_dim)\n",
    "        last_time_step_output = gru_out[:, -1, :]\n",
    "\n",
    "        # Pass through the fully connected layer\n",
    "        out = self.fc(last_time_step_output)\n",
    "\n",
    "        # Apply sigmoid activation\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "print(\"WeatherGRU model class defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f21d466",
   "metadata": {},
   "source": [
    "# 5. Baseline Model Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86510a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encapsulates the training loop, including loss calculation, optimization,\n",
    "# learning rate scheduling, validation, and saving the best model state based on validation loss.\n",
    "\n",
    "def train_baseline_model(model, train_loader, val_loader, config):\n",
    "    \"\"\"\n",
    "    Trains the baseline GRU model.\n",
    "    Args:\n",
    "        model (nn.Module): The WeatherGRU model instance.\n",
    "        train_loader (DataLoader): DataLoader for the training set.\n",
    "        val_loader (DataLoader): DataLoader for the validation set.\n",
    "        config (Config): Configuration object containing hyperparameters.\n",
    "    Returns:\n",
    "        nn.Module: The trained model loaded with the best state observed during validation.\n",
    "    \"\"\"\n",
    "    criterion = nn.BCELoss() # Binary Cross-Entropy Loss for binary classification\n",
    "    # AdamW optimizer with specified learning rate and weight decay\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY)\n",
    "    # Cosine annealing learning rate scheduler\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=config.SCHEDULER_T_MAX, eta_min=config.SCHEDULER_ETA_MIN)\n",
    "\n",
    "    model.to(config.DEVICE) # Move model to the configured device (GPU or CPU)\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None # To store the state_dict of the best model\n",
    "\n",
    "    print(\"\\n--- Starting Baseline Model Training ---\")\n",
    "    for epoch in range(config.EPOCHS):\n",
    "        model.train() # Set model to training mode\n",
    "        total_train_loss = 0.0\n",
    "\n",
    "        # Progress bar for training batches\n",
    "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config.EPOCHS} [Train]\", leave=False)\n",
    "        for inputs, labels in train_bar:\n",
    "            inputs, labels = inputs.to(config.DEVICE), labels.to(config.DEVICE)\n",
    "\n",
    "            optimizer.zero_grad() # Clear previous gradients\n",
    "            outputs = model(inputs) # Forward pass\n",
    "            loss = criterion(outputs, labels) # Calculate loss\n",
    "            loss.backward() # Backpropagation\n",
    "            optimizer.step() # Update weights\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            train_bar.set_postfix(loss=f\"{loss.item():.4f}\") # Update progress bar description\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        # --- Validation Phase ---\n",
    "        model.eval() # Set model to evaluation mode\n",
    "        total_val_loss = 0.0\n",
    "        with torch.no_grad(): # Disable gradient calculations for validation\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(config.DEVICE), labels.to(config.DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        current_lr = optimizer.param_groups[0]['lr'] # Get current learning rate\n",
    "\n",
    "        builtin_print(f\"Epoch {epoch+1}/{config.EPOCHS}: Train Loss={avg_train_loss:.4f}, Val Loss={avg_val_loss:.4f}, LR={current_lr:.6f}\")\n",
    "\n",
    "        # --- Learning Rate Scheduler Step ---\n",
    "        scheduler.step()\n",
    "\n",
    "        # --- Save Best Model State ---\n",
    "        # Keep track of the model state that yields the lowest validation loss\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            # Use deepcopy to ensure the state isn't affected by further training\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            builtin_print(f\"  New best validation loss: {best_val_loss:.4f}. Saving model state.\")\n",
    "\n",
    "    # --- Load Best Model State ---\n",
    "    # After training completes, load the best state found during validation\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        builtin_print(f\"\\n--- Best model state loaded (Validation Loss: {best_val_loss:.4f}) ---\")\n",
    "    else:\n",
    "        builtin_print(\"\\n--- Warning: No best model state was saved. Check validation loss behavior. ---\")\n",
    "\n",
    "    print(\"--- Baseline Model Training Finished ---\")\n",
    "    return model\n",
    "\n",
    "print(\"Baseline model training function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77398aab",
   "metadata": {},
   "source": [
    "# 6. Execute Baseline Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c2a2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes the DataLoaders, instantiates the WeatherGRU model, trains it using the\n",
    "# `train_baseline_model` function, and saves the final trained model state dictionary.\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
    "builtin_print(\"Train and Validation DataLoaders created.\")\n",
    "\n",
    "# Initialize the WeatherGRU model\n",
    "baseline_model = WeatherGRU(\n",
    "    input_dim=Config.INPUT_DIM,\n",
    "    hidden_dim=Config.HIDDEN_DIM,\n",
    "    n_layers=Config.N_LAYERS,\n",
    "    output_dim=Config.OUTPUT_DIM,\n",
    "    dropout=Config.DROPOUT\n",
    ")\n",
    "builtin_print(f\"Baseline WeatherGRU model initialized with {count_parameters(baseline_model):,} parameters.\")\n",
    "\n",
    "# Train the model\n",
    "baseline_model_trained = train_baseline_model(\n",
    "    model=baseline_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    config=Config # Pass the whole config object\n",
    ")\n",
    "\n",
    "# Save the state dictionary of the trained baseline model\n",
    "try:\n",
    "    # It's generally recommended to save only the state_dict\n",
    "    torch.save(baseline_model_trained.state_dict(), Config.BASELINE_MODEL_SAVE_PATH)\n",
    "    builtin_print(f\"\\nBaseline model state dictionary saved successfully to {Config.BASELINE_MODEL_SAVE_PATH}\")\n",
    "except Exception as e:\n",
    "    builtin_print(f\"\\nError saving baseline model state dictionary: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
