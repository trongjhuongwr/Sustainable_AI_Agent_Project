{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29acef2f",
   "metadata": {
    "papermill": {
     "duration": 0.003277,
     "end_time": "2025-12-23T17:30:06.157927",
     "exception": false,
     "start_time": "2025-12-23T17:30:06.154650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# =============================================================================\n",
    "# REINFORCEMENT LEARNING AGENT TRAINING NOTEBOOK\n",
    "# =============================================================================\n",
    "## Purpose:\n",
    "    - Define the custom RL Environment (`SustainableAIAgentEnv`) with fail-safe reward mechanisms.\n",
    "    - Implement a Proximal Policy Optimization (PPO) agent with entropy regularization.\n",
    "    - Conduct a comparative benchmark against a Random Search strategy.\n",
    "    - Save the best-performing policy and metrics for final evaluation.\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d775e4",
   "metadata": {
    "papermill": {
     "duration": 0.002282,
     "end_time": "2025-12-23T17:30:06.162900",
     "exception": false,
     "start_time": "2025-12-23T17:30:06.160618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# === Clone Repository & Install Dependencies ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9dab3ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T17:30:06.168895Z",
     "iopub.status.busy": "2025-12-23T17:30:06.168614Z",
     "iopub.status.idle": "2025-12-23T17:30:07.235823Z",
     "shell.execute_reply": "2025-12-23T17:30:07.234908Z"
    },
    "papermill": {
     "duration": 1.071944,
     "end_time": "2025-12-23T17:30:07.237284",
     "exception": false,
     "start_time": "2025-12-23T17:30:06.165340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Sustainable_AI_Agent_Project'...\r\n",
      "remote: Enumerating objects: 68, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (68/68), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (51/51), done.\u001b[K\r\n",
      "remote: Total 68 (delta 26), reused 54 (delta 15), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (68/68), 1.16 MiB | 8.67 MiB/s, done.\r\n",
      "Resolving deltas: 100% (26/26), done.\r\n",
      "/kaggle/working/Sustainable_AI_Agent_Project\n"
     ]
    }
   ],
   "source": [
    "# Use if run on Kaggle\n",
    "!rm -rf Sustainable_AI_Agent_Project\n",
    "!git clone https://github.com/trongjhuongwr/Sustainable_AI_Agent_Project.git\n",
    "%cd Sustainable_AI_Agent_Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb32dd16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T17:30:07.249699Z",
     "iopub.status.busy": "2025-12-23T17:30:07.249276Z",
     "iopub.status.idle": "2025-12-23T17:32:53.372055Z",
     "shell.execute_reply": "2025-12-23T17:32:53.371252Z"
    },
    "papermill": {
     "duration": 166.130994,
     "end_time": "2025-12-23T17:32:53.373471",
     "exception": false,
     "start_time": "2025-12-23T17:30:07.242477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m118.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m129.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m132.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.6/357.6 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.2/70.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "kaggle-environments 1.18.0 requires shimmy>=1.2.1, but you have shimmy 1.1.0 which is incompatible.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires ale-py>=0.10.1, but you have ale-py 0.8.1 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "tokenizers 0.21.2 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 1.0.0rc2 which is incompatible.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.5.1+cu121 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "google-genai 1.27.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.5.1+cu121 which is incompatible.\r\n",
      "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.27.2 which is incompatible.\r\n",
      "transformers 4.53.3 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.0rc2 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.4.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q --extra-index-url https://download.pytorch.org/whl/cu121 -r /kaggle/working/Sustainable_AI_Agent_Project/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0f73846",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T17:32:53.425350Z",
     "iopub.status.busy": "2025-12-23T17:32:53.425102Z",
     "iopub.status.idle": "2025-12-23T17:32:54.957552Z",
     "shell.execute_reply": "2025-12-23T17:32:54.956595Z"
    },
    "papermill": {
     "duration": 1.559752,
     "end_time": "2025-12-23T17:32:54.958973",
     "exception": false,
     "start_time": "2025-12-23T17:32:53.399221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torchvision 0.21.0+cu124\r\n",
      "Uninstalling torchvision-0.21.0+cu124:\r\n",
      "  Successfully uninstalled torchvision-0.21.0+cu124\r\n",
      "Torchvision uninstalled.\n"
     ]
    }
   ],
   "source": [
    "# Uninstall torchvision to prevent import conflicts with ptflops/pytorch\n",
    "!pip uninstall -y torchvision\n",
    "print(\"Torchvision uninstalled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce72446",
   "metadata": {
    "papermill": {
     "duration": 0.024987,
     "end_time": "2025-12-23T17:32:55.010048",
     "exception": false,
     "start_time": "2025-12-23T17:32:54.985061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Import Libraries and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c81c8df3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T17:32:55.061765Z",
     "iopub.status.busy": "2025-12-23T17:32:55.061015Z",
     "iopub.status.idle": "2025-12-23T17:33:10.994175Z",
     "shell.execute_reply": "2025-12-23T17:33:10.993319Z"
    },
    "papermill": {
     "duration": 15.960449,
     "end_time": "2025-12-23T17:33:10.995387",
     "exception": false,
     "start_time": "2025-12-23T17:32:55.034938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-23 17:33:00.382452: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1766511180.559107      20 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1766511180.609266      20 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "import json\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# Suppress specific warnings for cleaner output\n",
    "os.environ[\"GYM_DISABLE_WARNINGS\"] = \"true\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", module=\"gymnasium\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "logging.getLogger(\"gymnasium\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"stable_baselines3\").setLevel(logging.ERROR)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from sklearn.metrics import accuracy_score\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from codecarbon import EmissionsTracker\n",
    "from ptflops import get_model_complexity_info\n",
    "import torch_pruning as tp\n",
    "from tqdm.notebook import tqdm\n",
    "from builtins import print as builtin_print\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f370c168",
   "metadata": {
    "papermill": {
     "duration": 0.02524,
     "end_time": "2025-12-23T17:33:11.046761",
     "exception": false,
     "start_time": "2025-12-23T17:33:11.021521",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Configuration Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "480ca9f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T17:33:11.098649Z",
     "iopub.status.busy": "2025-12-23T17:33:11.098092Z",
     "iopub.status.idle": "2025-12-23T17:33:11.160420Z",
     "shell.execute_reply": "2025-12-23T17:33:11.159680Z"
    },
    "papermill": {
     "duration": 0.089458,
     "end_time": "2025-12-23T17:33:11.161495",
     "exception": false,
     "start_time": "2025-12-23T17:33:11.072037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded. Using device: cuda\n",
      "Seed set to: 42\n",
      "Loading processed data from: /kaggle/input/baseline-model-saa/processed_data.pt\n",
      "Loading baseline model from: /kaggle/input/baseline-model-saa/baseline_model.pth\n",
      "Agent will be saved to: /kaggle/working/sustainable_ai_agent_expanded.zip\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    # --- Input/Output Paths ---\n",
    "    PROCESSED_DATA_PATH = '/kaggle/input/baseline-model-saa/processed_data.pt'\n",
    "    BASELINE_MODEL_PATH = '/kaggle/input/baseline-model-saa/baseline_model.pth'\n",
    "    AGENT_SAVE_PATH = \"/kaggle/working/sustainable_ai_agent_expanded.zip\" # New Name\n",
    "    BEST_ACTION_SAVE_PATH = \"/kaggle/working/best_action_expanded.json\"   # New Name\n",
    "    \n",
    "    # --- Data & Model Params ---\n",
    "    SEQUENCE_LENGTH = 30\n",
    "    INPUT_DIM = 4\n",
    "    HIDDEN_DIM = 256\n",
    "    N_LAYERS = 2\n",
    "    OUTPUT_DIM = 1\n",
    "    DROPOUT = 0.2\n",
    "    \n",
    "    # --- RL Hyperparameters ---\n",
    "    SEED = 42\n",
    "    # Increased timesteps because search space is 8x larger (16 -> 128)\n",
    "    TOTAL_TIMESTEPS = 50000 \n",
    "    \n",
    "    # Reward Shaping\n",
    "    ACCURACY_PENALTY_THRESHOLD = 0.98\n",
    "    ACC_REWARD_SCALE = 20.0\n",
    "    FLOPS_REWARD_SCALE = 2.0\n",
    "    PARAMS_REWARD_SCALE = 1.0\n",
    "    \n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === 3. Reproducibility ===\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(Config.SEED)\n",
    "\n",
    "print(f\"Configuration loaded. Using device: {Config.DEVICE}\")\n",
    "print(f\"Seed set to: {Config.SEED}\")\n",
    "print(f\"Loading processed data from: {Config.PROCESSED_DATA_PATH}\")\n",
    "print(f\"Loading baseline model from: {Config.BASELINE_MODEL_PATH}\")\n",
    "print(f\"Agent will be saved to: {Config.AGENT_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387e1e42",
   "metadata": {
    "papermill": {
     "duration": 0.025469,
     "end_time": "2025-12-23T17:33:11.213689",
     "exception": false,
     "start_time": "2025-12-23T17:33:11.188220",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Utility Functions and Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fa90f92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T17:33:11.265061Z",
     "iopub.status.busy": "2025-12-23T17:33:11.264713Z",
     "iopub.status.idle": "2025-12-23T17:33:11.269571Z",
     "shell.execute_reply": "2025-12-23T17:33:11.268975Z"
    },
    "papermill": {
     "duration": 0.031633,
     "end_time": "2025-12-23T17:33:11.270600",
     "exception": false,
     "start_time": "2025-12-23T17:33:11.238967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WeatherGRU(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(WeatherGRU, self).__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=config.INPUT_DIM,\n",
    "            hidden_size=config.HIDDEN_DIM,\n",
    "            num_layers=config.N_LAYERS,\n",
    "            batch_first=True,\n",
    "            dropout=config.DROPOUT if config.N_LAYERS > 1 else 0\n",
    "        )\n",
    "        self.fc = nn.Linear(config.HIDDEN_DIM, config.OUTPUT_DIM)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8a39ac",
   "metadata": {
    "papermill": {
     "duration": 0.025334,
     "end_time": "2025-12-23T17:33:11.321985",
     "exception": false,
     "start_time": "2025-12-23T17:33:11.296651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Optimization Primitives (Pruning & Quantization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33bc3a32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T17:33:11.374210Z",
     "iopub.status.busy": "2025-12-23T17:33:11.373935Z",
     "iopub.status.idle": "2025-12-23T17:33:11.380700Z",
     "shell.execute_reply": "2025-12-23T17:33:11.380139Z"
    },
    "papermill": {
     "duration": 0.033883,
     "end_time": "2025-12-23T17:33:11.381824",
     "exception": false,
     "start_time": "2025-12-23T17:33:11.347941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"Calculates the effective number of non-zero parameters in the model.\"\"\"\n",
    "    total_params = 0\n",
    "    for p in model.parameters():\n",
    "        if p.requires_grad:\n",
    "            total_params += torch.count_nonzero(p).item()\n",
    "    return total_params\n",
    "\n",
    "def apply_layerwise_pruning(model, l0_rate, l1_rate, linear_rate):\n",
    "    \"\"\"\n",
    "    Implements Deep Granular Pruning Strategy:\n",
    "    - l0_rate: Pruning rate for GRU Layer 0 (Feature Extraction Layer - Sensitive).\n",
    "    - l1_rate: Pruning rate for GRU Layer 1 (Abstract Representation Layer - Redundant).\n",
    "    - linear_rate: Pruning rate for the Linear Readout Layer.\n",
    "    \"\"\"\n",
    "    model_copy = copy.deepcopy(model)\n",
    "    \n",
    "    # 1. Layer-wise GRU Pruning\n",
    "    for module in model_copy.modules():\n",
    "        if isinstance(module, nn.GRU):\n",
    "            for name_param, param in list(module.named_parameters()):\n",
    "                if 'weight' in name_param:\n",
    "                    # Identify layer index based on parameter name convention\n",
    "                    if 'l0' in name_param:   # Layer 0\n",
    "                        rate = l0_rate\n",
    "                    elif 'l1' in name_param: # Layer 1\n",
    "                        rate = l1_rate\n",
    "                    else:\n",
    "                        rate = 0.0\n",
    "                    \n",
    "                    if rate > 0:\n",
    "                        prune.l1_unstructured(module, name=name_param, amount=rate)\n",
    "                        prune.remove(module, name=name_param)\n",
    "\n",
    "    # 2. Linear Layer Pruning\n",
    "    if linear_rate > 0:\n",
    "        for module in model_copy.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                prune.l1_unstructured(module, name='weight', amount=linear_rate)\n",
    "                prune.remove(module, name='weight')\n",
    "                \n",
    "    return model_copy\n",
    "\n",
    "def apply_quantization(model):\n",
    "    \"\"\"Applies dynamic quantization (Int8) to reduce model size and inference latency.\"\"\"\n",
    "    model_copy = copy.deepcopy(model)\n",
    "    model_copy.to('cpu')\n",
    "    model_copy.eval()\n",
    "    quantized_model = torch.quantization.quantize_dynamic(\n",
    "        model_copy, {nn.Linear, nn.GRU}, dtype=torch.qint8\n",
    "    )\n",
    "    return quantized_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4fe23f",
   "metadata": {
    "papermill": {
     "duration": 0.025511,
     "end_time": "2025-12-23T17:33:11.433932",
     "exception": false,
     "start_time": "2025-12-23T17:33:11.408421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Custom RL Environment with Fail-Safe Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "effe347b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T17:33:11.486649Z",
     "iopub.status.busy": "2025-12-23T17:33:11.486130Z",
     "iopub.status.idle": "2025-12-23T17:33:11.499445Z",
     "shell.execute_reply": "2025-12-23T17:33:11.498902Z"
    },
    "papermill": {
     "duration": 0.041532,
     "end_time": "2025-12-23T17:33:11.500516",
     "exception": false,
     "start_time": "2025-12-23T17:33:11.458984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [REPLACEMENT FOR CELL 8]\n",
    "class SustainableAIAgentEnvExpanded(gym.Env):\n",
    "    \"\"\"\n",
    "    Continuous Deep Control Environment for Eco-friendly AI Optimization.\n",
    "    Action Space (4D Continuous Box): [GRU_L0, GRU_L1, Linear, Quantization_Prob]\n",
    "    \"\"\"\n",
    "    def __init__(self, baseline_model, val_loader, config):\n",
    "        super(SustainableAIAgentEnvExpanded, self).__init__()\n",
    "        self.baseline_model = baseline_model\n",
    "        self.val_loader = val_loader\n",
    "        self.config = config\n",
    "        \n",
    "        # Initialize Baseline Benchmarks\n",
    "        self.baseline_metrics = self._evaluate_performance(self.baseline_model)\n",
    "        if self.baseline_metrics['flops'] < 1000: self.baseline_metrics['flops'] = 1e6\n",
    "        print(f\"Baseline Benchmark Metrics: {self.baseline_metrics}\")\n",
    "        \n",
    "        # --- Continuous Action Space ---\n",
    "        # 0: GRU Layer 0 Pruning Rate (0.0 - 1.0)\n",
    "        # 1: GRU Layer 1 Pruning Rate (0.0 - 1.0)\n",
    "        # 2: Linear Pruning Rate (0.0 - 1.0)\n",
    "        # 3: Quantization Probability (Threshold > 0.5 triggers quantization)\n",
    "        self.action_space = spaces.Box(low=0.0, high=1.0, shape=(4,), dtype=np.float32)\n",
    "        \n",
    "        # Observation Space: [Accuracy, Accuracy_Delta, Param_Reduction, FLOPs_Reduction]\n",
    "        self.observation_space = spaces.Box(low=-1.0, high=1.0, shape=(4,), dtype=np.float32)\n",
    "\n",
    "    def _evaluate_performance(self, model):\n",
    "        # (Logic giữ nguyên nhưng đảm bảo tính đúng đắn cho Quantization)\n",
    "        model.eval()\n",
    "        is_quantized = any(\"quantized\" in str(type(m)).lower() for m in model.modules())\n",
    "        device = torch.device(\"cpu\") if is_quantized else self.config.DEVICE\n",
    "        model.to(device)\n",
    "        \n",
    "        y_true, y_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for X, y in self.val_loader:\n",
    "                X = X.to(device)\n",
    "                preds = (model(X) > 0.5).float()\n",
    "                y_true.extend(y.cpu().numpy())\n",
    "                y_pred.extend(preds.cpu().numpy())\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        \n",
    "        params = count_parameters(model)\n",
    "        baseline_p = self.baseline_metrics['params'] if hasattr(self, 'baseline_metrics') else params\n",
    "        if baseline_p == 0: baseline_p = 1\n",
    "        param_ratio = params / baseline_p\n",
    "        \n",
    "        baseline_f = self.baseline_metrics['flops'] if hasattr(self, 'baseline_metrics') else 1e6\n",
    "        quant_factor = 0.25 if is_quantized else 1.0\n",
    "        flops = baseline_f * param_ratio * quant_factor\n",
    "        \n",
    "        return {\"accuracy\": accuracy, \"params\": params, \"flops\": flops}\n",
    "\n",
    "    def step(self, action):\n",
    "        # 1. Decode Continuous Actions\n",
    "        # Clip to safe ranges (e.g., max 90% pruning to prevent total information loss)\n",
    "        l0_rate = np.clip(action[0], 0.0, 0.90) \n",
    "        l1_rate = np.clip(action[1], 0.0, 0.95) # Layer 1 is more redundant, allow higher pruning\n",
    "        linear_rate = np.clip(action[2], 0.0, 0.95)\n",
    "        \n",
    "        # Quantization Decision\n",
    "        use_quantization = action[3] > 0.5\n",
    "        \n",
    "        # 2. Apply Deep Granular Optimizations\n",
    "        current_model = copy.deepcopy(self.baseline_model)\n",
    "        current_model = apply_layerwise_pruning(current_model, l0_rate, l1_rate, linear_rate)\n",
    "        \n",
    "        if use_quantization:\n",
    "            current_model = apply_quantization(current_model)\n",
    "            \n",
    "        # 3. Evaluate\n",
    "        metrics = self._evaluate_performance(current_model)\n",
    "        \n",
    "        # 4. Calculate Reward (Multi-objective)\n",
    "        acc_drop = metrics['accuracy'] - self.baseline_metrics['accuracy']\n",
    "        flops_reduction = 1.0 - (metrics['flops'] / self.baseline_metrics['flops'])\n",
    "        params_reduction = 1.0 - (metrics['params'] / self.baseline_metrics['params'])\n",
    "        \n",
    "        # Penalty for significant accuracy degradation (>5% drop)\n",
    "        if metrics['accuracy'] < (self.baseline_metrics['accuracy'] * 0.95):\n",
    "            acc_reward = -10.0\n",
    "        else:\n",
    "            acc_reward = acc_drop * self.config.ACC_REWARD_SCALE\n",
    "            \n",
    "        eff_reward = (flops_reduction * self.config.FLOPS_REWARD_SCALE) + \\\n",
    "                     (params_reduction * self.config.PARAMS_REWARD_SCALE)\n",
    "        \n",
    "        total_reward = acc_reward + eff_reward\n",
    "        \n",
    "        obs = np.array([metrics['accuracy'], acc_drop, params_reduction, flops_reduction], dtype=np.float32)\n",
    "        \n",
    "        info = {\n",
    "            \"gru_l0\": l0_rate,\n",
    "            \"gru_l1\": l1_rate,\n",
    "            \"linear\": linear_rate,\n",
    "            \"quant\": use_quantization,\n",
    "            \"accuracy\": metrics['accuracy'],\n",
    "            \"reward\": total_reward\n",
    "        }\n",
    "        \n",
    "        return obs, total_reward, True, False, info\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        super().reset(seed=seed)\n",
    "        obs = np.array([self.baseline_metrics['accuracy'], 0.0, 0.0, 0.0], dtype=np.float32)\n",
    "        return obs, {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa4ccba",
   "metadata": {
    "papermill": {
     "duration": 0.025164,
     "end_time": "2025-12-23T17:33:11.550772",
     "exception": false,
     "start_time": "2025-12-23T17:33:11.525608",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Main Execution Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "921279ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T17:33:11.604201Z",
     "iopub.status.busy": "2025-12-23T17:33:11.603693Z",
     "iopub.status.idle": "2025-12-23T18:13:28.554762Z",
     "shell.execute_reply": "2025-12-23T18:13:28.553809Z"
    },
    "papermill": {
     "duration": 2416.980149,
     "end_time": "2025-12-23T18:13:28.556152",
     "exception": false,
     "start_time": "2025-12-23T17:33:11.576003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model loaded successfully.\n",
      "Baseline Benchmark Metrics: {'accuracy': 0.6608695652173913, 'params': 596225, 'flops': 1000000.0}\n",
      "\n",
      "--- Initiating Continuous PPO Training (Deep Layer-wise Optimization) ---\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -1.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 42       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 48       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | -0.465     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 41         |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 98         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03610345 |\n",
      "|    clip_fraction        | 0.375      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.64      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.37       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.101     |\n",
      "|    std                  | 0.984      |\n",
      "|    value_loss           | 18.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 1.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029033009 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.57       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.74        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0902     |\n",
      "|    std                  | 0.97        |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 1.08       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 37         |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 218        |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03514194 |\n",
      "|    clip_fraction        | 0.411      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.5       |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.64       |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0789    |\n",
      "|    std                  | 0.951      |\n",
      "|    value_loss           | 9.95       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 1.8        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 35         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 291        |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04895702 |\n",
      "|    clip_fraction        | 0.515      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.42      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.7        |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0833    |\n",
      "|    std                  | 0.937      |\n",
      "|    value_loss           | 7.39       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 1.89       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 32         |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 375        |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06950879 |\n",
      "|    clip_fraction        | 0.535      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.32      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.8        |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0846    |\n",
      "|    std                  | 0.909      |\n",
      "|    value_loss           | 5.22       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 2.35       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 30         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 471        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06794857 |\n",
      "|    clip_fraction        | 0.548      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.18      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.08       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0933    |\n",
      "|    std                  | 0.885      |\n",
      "|    value_loss           | 3.47       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 2.68        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 572         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039869513 |\n",
      "|    clip_fraction        | 0.418       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.05       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0751     |\n",
      "|    std                  | 0.861       |\n",
      "|    value_loss           | 2.85        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 2.67        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 674         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030312305 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.92       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.255       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.068      |\n",
      "|    std                  | 0.842       |\n",
      "|    value_loss           | 1.74        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 2.95        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 778         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019115383 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.81       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.149       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0536     |\n",
      "|    std                  | 0.823       |\n",
      "|    value_loss           | 1.35        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 2.88        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 884         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021029647 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.69       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00308    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0461     |\n",
      "|    std                  | 0.797       |\n",
      "|    value_loss           | 0.651       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 2.91        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 24          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 993         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017325846 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.56       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0694      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    std                  | 0.773       |\n",
      "|    value_loss           | 0.766       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 3.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 24          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 1103        |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019302659 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.43       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0391     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    std                  | 0.751       |\n",
      "|    value_loss           | 0.483       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 3.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 1212        |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014259913 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.3        |\n",
      "|    explained_variance   | 1.79e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.068      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    std                  | 0.726       |\n",
      "|    value_loss           | 0.341       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 3.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 1325        |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012717191 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.17       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0248     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    std                  | 0.706       |\n",
      "|    value_loss           | 0.336       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | 3.08         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 22           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 1436         |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105414055 |\n",
      "|    clip_fraction        | 0.16         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.07        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0221      |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.0206      |\n",
      "|    std                  | 0.691        |\n",
      "|    value_loss           | 0.46         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 3.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 1547        |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015166981 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.98       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.765       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    std                  | 0.676       |\n",
      "|    value_loss           | 0.255       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 3.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 1657        |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015359007 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.88       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0284      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0267     |\n",
      "|    std                  | 0.658       |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 3.01       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 22         |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 1763       |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02136314 |\n",
      "|    clip_fraction        | 0.305      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.79      |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0703    |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0331    |\n",
      "|    std                  | 0.645      |\n",
      "|    value_loss           | 0.162      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 3.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 1872        |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027335124 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.72       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0632     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    std                  | 0.633       |\n",
      "|    value_loss           | 0.298       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 3.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 1980        |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041805744 |\n",
      "|    clip_fraction        | 0.487       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.64       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0343     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0557     |\n",
      "|    std                  | 0.618       |\n",
      "|    value_loss           | 0.314       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 3.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 2087        |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053768538 |\n",
      "|    clip_fraction        | 0.505       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.52       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.81        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0599     |\n",
      "|    std                  | 0.595       |\n",
      "|    value_loss           | 0.406       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 3.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 2195        |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053211857 |\n",
      "|    clip_fraction        | 0.494       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.36       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.803       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0735     |\n",
      "|    std                  | 0.567       |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 3.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 2303        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046839625 |\n",
      "|    clip_fraction        | 0.47        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.2        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.107      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0806     |\n",
      "|    std                  | 0.541       |\n",
      "|    value_loss           | 0.0979      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 3.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 2412        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036059845 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.02       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.108      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0658     |\n",
      "|    std                  | 0.515       |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "Training Procedure Concluded.\n",
      "\n",
      "--- Optimal Strategy Discovered (Global Optimum) ---\n",
      "GRU Layer 0 Pruning Rate (Feature Extraction): 0.00%\n",
      "GRU Layer 1 Pruning Rate (Abstract Representation): 95.00%\n",
      "Linear Readout Pruning Rate: 95.00%\n",
      "Dynamic Quantization Applied: True\n",
      "Resulting Accuracy: 0.6783\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Data & Baseline\n",
    "try:\n",
    "    processed_data = torch.load(Config.PROCESSED_DATA_PATH)\n",
    "    val_dataset = TensorDataset(processed_data['X_val'], processed_data['y_val'])\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "    baseline_model = WeatherGRU(Config)\n",
    "    baseline_model.load_state_dict(torch.load(Config.BASELINE_MODEL_PATH))\n",
    "    print(\"Baseline Model loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Critical Error: Artifacts not found. {e}\")\n",
    "\n",
    "# 2. Initialize Continuous Environment\n",
    "env = SustainableAIAgentEnvExpanded(baseline_model, val_loader, Config)\n",
    "\n",
    "# 3. Train PPO Agent (Continuous Policy)\n",
    "print(\"\\n--- Initiating Continuous PPO Training (Deep Layer-wise Optimization) ---\")\n",
    "checkpoint_callback = CheckpointCallback(save_freq=5000, save_path='/kaggle/working/checkpoints_expanded/', name_prefix='ppo_continuous')\n",
    "\n",
    "# MlpPolicy handles continuous spaces automatically\n",
    "agent = PPO(\"MlpPolicy\", env, verbose=1, seed=Config.SEED, ent_coef=0.01, device=Config.DEVICE)\n",
    "agent.learn(total_timesteps=Config.TOTAL_TIMESTEPS, callback=checkpoint_callback)\n",
    "agent.save(Config.AGENT_SAVE_PATH)\n",
    "print(\"Training Procedure Concluded.\")\n",
    "\n",
    "# 4. Extract & Validate Best Strategy\n",
    "obs, _ = env.reset()\n",
    "action, _ = agent.predict(obs, deterministic=True)\n",
    "_, _, _, _, best_info = env.step(action)\n",
    "\n",
    "print(\"\\n--- Optimal Strategy Discovered (Global Optimum) ---\")\n",
    "print(f\"GRU Layer 0 Pruning Rate (Feature Extraction): {best_info['gru_l0']*100:.2f}%\")\n",
    "print(f\"GRU Layer 1 Pruning Rate (Abstract Representation): {best_info['gru_l1']*100:.2f}%\")\n",
    "print(f\"Linear Readout Pruning Rate: {best_info['linear']*100:.2f}%\")\n",
    "print(f\"Dynamic Quantization Applied: {best_info['quant']}\")\n",
    "print(f\"Resulting Accuracy: {best_info['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e3ff084",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T18:13:28.611137Z",
     "iopub.status.busy": "2025-12-23T18:13:28.610549Z",
     "iopub.status.idle": "2025-12-23T18:13:28.616089Z",
     "shell.execute_reply": "2025-12-23T18:13:28.615439Z"
    },
    "papermill": {
     "duration": 0.033814,
     "end_time": "2025-12-23T18:13:28.617101",
     "exception": false,
     "start_time": "2025-12-23T18:13:28.583287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal policy parameters saved to /kaggle/working/best_action_expanded.json\n"
     ]
    }
   ],
   "source": [
    "# 5. Save for Final Evaluation\n",
    "with open(Config.BEST_ACTION_SAVE_PATH, 'w') as f:\n",
    "    json.dump({\n",
    "        \"gru_l0_rate\": float(best_info['gru_l0']),\n",
    "        \"gru_l1_rate\": float(best_info['gru_l1']),\n",
    "        \"linear_pruning_rate\": float(best_info['linear']),\n",
    "        \"quantization\": bool(best_info['quant'])\n",
    "    }, f)\n",
    "print(f\"Optimal policy parameters saved to {Config.BEST_ACTION_SAVE_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1868601,
     "sourceId": 3051857,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8585703,
     "sourceId": 14254451,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2609.059914,
   "end_time": "2025-12-23T18:13:31.514807",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-23T17:30:02.454893",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
