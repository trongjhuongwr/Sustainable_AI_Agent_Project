{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23954a7c",
   "metadata": {
    "papermill": {
     "duration": 0.002653,
     "end_time": "2025-12-22T09:27:05.927211",
     "exception": false,
     "start_time": "2025-12-22T09:27:05.924558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# =============================================================================\n",
    "# BASELINE MODEL TRAINING NOTEBOOK\n",
    "# =============================================================================\n",
    "## Purpose:\n",
    "    - Establish a deterministic environment for reproducibility.\n",
    "    - Load and preprocess the time-series weather dataset (Seattle Weather).\n",
    "    - Define the baseline Gated Recurrent Unit (GRU) architecture.\n",
    "    - Train the model using a standard supervised learning approach.\n",
    "    - Save the optimized model weights and processed tensors for the RL stage.\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7237350",
   "metadata": {
    "papermill": {
     "duration": 0.001813,
     "end_time": "2025-12-22T09:27:05.931496",
     "exception": false,
     "start_time": "2025-12-22T09:27:05.929683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# === Clone Repository & Install Dependencies ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52d1777a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T09:27:05.937181Z",
     "iopub.status.busy": "2025-12-22T09:27:05.936405Z",
     "iopub.status.idle": "2025-12-22T09:27:07.568983Z",
     "shell.execute_reply": "2025-12-22T09:27:07.567865Z"
    },
    "papermill": {
     "duration": 1.636668,
     "end_time": "2025-12-22T09:27:07.570155",
     "exception": false,
     "start_time": "2025-12-22T09:27:05.933487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Sustainable_AI_Agent_Project'...\r\n",
      "remote: Enumerating objects: 68, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (68/68), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (51/51), done.\u001b[K\r\n",
      "remote: Total 68 (delta 26), reused 54 (delta 15), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (68/68), 1.16 MiB | 5.17 MiB/s, done.\r\n",
      "Resolving deltas: 100% (26/26), done.\r\n",
      "/kaggle/working/Sustainable_AI_Agent_Project\n"
     ]
    }
   ],
   "source": [
    "# Use if run on Kaggle\n",
    "!rm -rf Sustainable_AI_Agent_Project\n",
    "!git clone https://github.com/trongjhuongwr/Sustainable_AI_Agent_Project.git\n",
    "%cd Sustainable_AI_Agent_Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59624f59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T09:27:07.576558Z",
     "iopub.status.busy": "2025-12-22T09:27:07.576285Z",
     "iopub.status.idle": "2025-12-22T09:30:21.918514Z",
     "shell.execute_reply": "2025-12-22T09:30:21.917696Z"
    },
    "papermill": {
     "duration": 194.346903,
     "end_time": "2025-12-22T09:30:21.919979",
     "exception": false,
     "start_time": "2025-12-22T09:27:07.573076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m118.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.6/357.6 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.2/70.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "kaggle-environments 1.18.0 requires shimmy>=1.2.1, but you have shimmy 1.1.0 which is incompatible.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires ale-py>=0.10.1, but you have ale-py 0.8.1 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "tokenizers 0.21.2 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 1.0.0rc2 which is incompatible.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.5.1+cu121 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "google-genai 1.27.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.5.1+cu121 which is incompatible.\r\n",
      "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.27.2 which is incompatible.\r\n",
      "transformers 4.53.3 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.0rc2 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.4.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q --extra-index-url https://download.pytorch.org/whl/cu121 -r /kaggle/working/Sustainable_AI_Agent_Project/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f656ec81",
   "metadata": {
    "papermill": {
     "duration": 0.026198,
     "end_time": "2025-12-22T09:30:21.973226",
     "exception": false,
     "start_time": "2025-12-22T09:30:21.947028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Import Libraries and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c223dfff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T09:30:22.025937Z",
     "iopub.status.busy": "2025-12-22T09:30:22.025199Z",
     "iopub.status.idle": "2025-12-22T09:30:24.820155Z",
     "shell.execute_reply": "2025-12-22T09:30:24.819289Z"
    },
    "papermill": {
     "duration": 2.822259,
     "end_time": "2025-12-22T09:30:24.821313",
     "exception": false,
     "start_time": "2025-12-22T09:30:21.999054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "os.environ[\"GYM_DISABLE_WARNINGS\"] = \"true\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", module=\"gymnasium\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "logging.getLogger(\"gymnasium\").setLevel(logging.ERROR)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from builtins import print as builtin_print\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38540dc",
   "metadata": {
    "papermill": {
     "duration": 0.025256,
     "end_time": "2025-12-22T09:30:24.872596",
     "exception": false,
     "start_time": "2025-12-22T09:30:24.847340",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Configuration Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca209b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T09:30:24.924481Z",
     "iopub.status.busy": "2025-12-22T09:30:24.923715Z",
     "iopub.status.idle": "2025-12-22T09:30:24.986348Z",
     "shell.execute_reply": "2025-12-22T09:30:24.985564Z"
    },
    "papermill": {
     "duration": 0.08977,
     "end_time": "2025-12-22T09:30:24.987466",
     "exception": false,
     "start_time": "2025-12-22T09:30:24.897696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded. Using device: cuda\n",
      "Seed set to: 42\n",
      "Processed data will be saved to: /kaggle/working/processed_data.pt\n",
      "Baseline model will be saved to: /kaggle/working/baseline_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Defines hyperparameters, file paths, and other parameters used throughout the baseline training process.\n",
    "class Config:\n",
    "    # --- Data Paths ---\n",
    "    DATA_PATH = '/kaggle/input/weather-prediction/seattle-weather.csv' # Path to the raw dataset CSV file\n",
    "    PROCESSED_DATA_SAVE_PATH = '/kaggle/working/processed_data.pt'     # Output path for saving processed data tensors\n",
    "    BASELINE_MODEL_SAVE_PATH = '/kaggle/working/baseline_model.pth'    # Output path for saving the trained baseline model state dictionary\n",
    "\n",
    "    # --- Data Preprocessing Parameters ---\n",
    "    SEQUENCE_LENGTH = 30      # Number of past days used to predict the next day\n",
    "    TEST_SIZE = 0.2           # Proportion of data reserved for the final test set\n",
    "    VAL_SIZE = 0.1            # Proportion of the remaining data (after test split) used for validation\n",
    "    SEED = 42                 # Random seed for reproducibility\n",
    "\n",
    "    # --- Model Architecture Parameters ---\n",
    "    INPUT_DIM = 4      # Number of input features: precipitation, temp_max, temp_min, wind\n",
    "    HIDDEN_DIM = 256   # Dimensionality of the GRU hidden state\n",
    "    N_LAYERS = 2       # Number of stacked GRU layers\n",
    "    OUTPUT_DIM = 1     # Output dimension (binary classification: rain probability)\n",
    "    DROPOUT = 0.2      # Dropout rate applied between GRU layers\n",
    "\n",
    "    # --- Training Hyperparameters ---\n",
    "    BATCH_SIZE = 64\n",
    "    EPOCHS = 100              # Number of training epochs\n",
    "    LEARNING_RATE = 1e-4      # AdamW initial learning rate\n",
    "    WEIGHT_DECAY = 1e-4       # Weight decay for AdamW optimizer\n",
    "    SCHEDULER_T_MAX = 50      # T_max for CosineAnnealingLR scheduler (cycle length)\n",
    "    SCHEDULER_ETA_MIN = 1e-6  # Minimum learning rate for scheduler\n",
    "\n",
    "    # --- Computation Device ---\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(Config.SEED)\n",
    "\n",
    "print(f\"Configuration loaded. Using device: {Config.DEVICE}\")\n",
    "print(f\"Seed set to: {Config.SEED}\")\n",
    "print(f\"Processed data will be saved to: {Config.PROCESSED_DATA_SAVE_PATH}\")\n",
    "print(f\"Baseline model will be saved to: {Config.BASELINE_MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714d1625",
   "metadata": {
    "papermill": {
     "duration": 0.024818,
     "end_time": "2025-12-22T09:30:25.038113",
     "exception": false,
     "start_time": "2025-12-22T09:30:25.013295",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b96335f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T09:30:25.089237Z",
     "iopub.status.busy": "2025-12-22T09:30:25.089002Z",
     "iopub.status.idle": "2025-12-22T09:30:25.134736Z",
     "shell.execute_reply": "2025-12-22T09:30:25.133715Z"
    },
    "papermill": {
     "duration": 0.072688,
     "end_time": "2025-12-22T09:30:25.136011",
     "exception": false,
     "start_time": "2025-12-22T09:30:25.063323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully. Shape: (1461, 6)\n",
      "Training Samples: 1029 | Validation: 115 | Test: 287\n",
      "Processed data saved to /kaggle/working/processed_data.pt\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_data(config):\n",
    "    \"\"\"\n",
    "    Loads raw data, performs feature scaling, generates sequences, \n",
    "    and creates PyTorch tensors for training.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing train/val/test loaders and tensors.\n",
    "    \"\"\"\n",
    "    # 1. Load Data\n",
    "    try:\n",
    "        df = pd.read_csv(config.DATA_PATH)\n",
    "        print(f\"Data loaded successfully. Shape: {df.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Dataset not found at {config.DATA_PATH}. Please verify the path.\")\n",
    "\n",
    "    # 2. Feature Engineering\n",
    "    # Convert categorical 'weather' to binary target (1: Rain/Drizzle, 0: Others)\n",
    "    df['target'] = df['weather'].apply(lambda x: 1 if x in ['rain', 'drizzle'] else 0)\n",
    "    features = ['precipitation', 'temp_max', 'temp_min', 'wind']\n",
    "    \n",
    "    # 3. Normalization (Min-Max Scaling) to [0, 1]\n",
    "    # Essential for neural network convergence\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_features = scaler.fit_transform(df[features])\n",
    "    targets = df['target'].values\n",
    "    \n",
    "    # 4. Sequence Generation (Sliding Window)\n",
    "    X, y = [], []\n",
    "    for i in range(len(scaled_features) - config.SEQUENCE_LENGTH):\n",
    "        X.append(scaled_features[i : i + config.SEQUENCE_LENGTH])\n",
    "        y.append(targets[i + config.SEQUENCE_LENGTH])\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # 5. Stratified Data Splitting\n",
    "    # Split Test Set\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y, test_size=config.TEST_SIZE, random_state=config.SEED, stratify=y\n",
    "    )\n",
    "    # Split Validation Set\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=config.VAL_SIZE, random_state=config.SEED, stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    # 6. Tensor Conversion\n",
    "    # Move data to GPU memory if available for faster training\n",
    "    tensors = {\n",
    "        'X_train': torch.FloatTensor(X_train),\n",
    "        'y_train': torch.FloatTensor(y_train).unsqueeze(1),\n",
    "        'X_val': torch.FloatTensor(X_val),\n",
    "        'y_val': torch.FloatTensor(y_val).unsqueeze(1),\n",
    "        'X_test': torch.FloatTensor(X_test),\n",
    "        'y_test': torch.FloatTensor(y_test).unsqueeze(1)\n",
    "    }\n",
    "    \n",
    "    print(f\"Training Samples: {len(X_train)} | Validation: {len(X_val)} | Test: {len(X_test)}\")\n",
    "    \n",
    "    # Save processed tensors for the RL Agent (Stage 2)\n",
    "    torch.save(tensors, config.PROCESSED_DATA_SAVE_PATH)\n",
    "    print(f\"Processed data saved to {config.PROCESSED_DATA_SAVE_PATH}\")\n",
    "    \n",
    "    return tensors\n",
    "\n",
    "# Execute preprocessing\n",
    "data_tensors = load_and_preprocess_data(Config)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(TensorDataset(data_tensors['X_train'], data_tensors['y_train']), \n",
    "                          batch_size=Config.BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(data_tensors['X_val'], data_tensors['y_val']), \n",
    "                        batch_size=Config.BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136f47eb",
   "metadata": {
    "papermill": {
     "duration": 0.02687,
     "end_time": "2025-12-22T09:30:25.189876",
     "exception": false,
     "start_time": "2025-12-22T09:30:25.163006",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Model Architecture (Baseline GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b166815e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T09:30:25.244501Z",
     "iopub.status.busy": "2025-12-22T09:30:25.244048Z",
     "iopub.status.idle": "2025-12-22T09:30:25.249175Z",
     "shell.execute_reply": "2025-12-22T09:30:25.248650Z"
    },
    "papermill": {
     "duration": 0.033351,
     "end_time": "2025-12-22T09:30:25.250157",
     "exception": false,
     "start_time": "2025-12-22T09:30:25.216806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WeatherGRU(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard Gated Recurrent Unit (GRU) architecture for time-series binary classification.\n",
    "    Constructed to serve as a baseline for subsequent compression experiments.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(WeatherGRU, self).__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=config.INPUT_DIM,\n",
    "            hidden_size=config.HIDDEN_DIM,\n",
    "            num_layers=config.N_LAYERS,\n",
    "            batch_first=True,\n",
    "            dropout=config.DROPOUT if config.N_LAYERS > 1 else 0\n",
    "        )\n",
    "        self.fc = nn.Linear(config.HIDDEN_DIM, config.OUTPUT_DIM)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, input_dim)\n",
    "        out, _ = self.gru(x)\n",
    "        \n",
    "        # Utilize the hidden state from the last time step\n",
    "        # out[:, -1, :] shape: (batch_size, hidden_dim)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376012c1",
   "metadata": {
    "papermill": {
     "duration": 0.026622,
     "end_time": "2025-12-22T09:30:25.302551",
     "exception": false,
     "start_time": "2025-12-22T09:30:25.275929",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Training Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe51c551",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T09:30:25.354732Z",
     "iopub.status.busy": "2025-12-22T09:30:25.354236Z",
     "iopub.status.idle": "2025-12-22T09:30:38.032454Z",
     "shell.execute_reply": "2025-12-22T09:30:38.031540Z"
    },
    "papermill": {
     "duration": 12.705682,
     "end_time": "2025-12-22T09:30:38.033670",
     "exception": false,
     "start_time": "2025-12-22T09:30:25.327988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initiating Baseline Training ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457642b880e24b95bc881f3632cb4cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed. Best Validation Loss: 0.5999\n",
      "Model checkpoint saved to /kaggle/working/baseline_model.pth\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, config):\n",
    "    \"\"\"\n",
    "    Executes the training loop with validation monitoring and model checkpointing.\n",
    "    \"\"\"\n",
    "    criterion = nn.BCELoss() # Binary Cross Entropy\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=config.EPOCHS)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    model.to(config.DEVICE)\n",
    "    \n",
    "    print(\"\\n--- Initiating Baseline Training ---\")\n",
    "    progress_bar = tqdm(range(config.EPOCHS), desc=\"Training Epochs\")\n",
    "    \n",
    "    for epoch in progress_bar:\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(config.DEVICE), y_batch.to(config.DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(config.DEVICE), y_batch.to(config.DEVICE)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Checkpointing\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), config.BASELINE_MODEL_SAVE_PATH)\n",
    "            \n",
    "        progress_bar.set_postfix({'Train Loss': f'{avg_train_loss:.4f}', 'Val Loss': f'{avg_val_loss:.4f}'})\n",
    "\n",
    "    print(f\"\\nTraining completed. Best Validation Loss: {best_val_loss:.4f}\")\n",
    "    print(f\"Model checkpoint saved to {config.BASELINE_MODEL_SAVE_PATH}\")\n",
    "\n",
    "# Initialize and Train\n",
    "baseline_model = WeatherGRU(Config)\n",
    "train_model(baseline_model, train_loader, val_loader, Config)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1868601,
     "sourceId": 3051857,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 218.02232,
   "end_time": "2025-12-22T09:30:40.248220",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-22T09:27:02.225900",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "04757055ed7c44459f095aa7280a2ca3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2ffa3ba1b44a4cd8ae2872d3c0367790": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "457642b880e24b95bc881f3632cb4cb5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c089db27af024fba80089d830c77a771",
        "IPY_MODEL_e1b7fbcea01a4f7980f047ea2e6f0379",
        "IPY_MODEL_c9bd6ef6ad5940aeab270114f3e05923"
       ],
       "layout": "IPY_MODEL_4cb41ca2a847486e909e1546c7f8dd2a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4cb41ca2a847486e909e1546c7f8dd2a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "518178aa3d604977b71e7dd21371e712": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "80390db82ddc454d8b0dbb7bb722ce91": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c089db27af024fba80089d830c77a771": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_518178aa3d604977b71e7dd21371e712",
       "placeholder": "​",
       "style": "IPY_MODEL_f6d3ec44cc8b441398e9e22f0a8bc278",
       "tabbable": null,
       "tooltip": null,
       "value": "Training Epochs: 100%"
      }
     },
     "c9bd6ef6ad5940aeab270114f3e05923": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2ffa3ba1b44a4cd8ae2872d3c0367790",
       "placeholder": "​",
       "style": "IPY_MODEL_d69f83f808e14ca1b292e42ee009be12",
       "tabbable": null,
       "tooltip": null,
       "value": " 100/100 [00:09&lt;00:00, 10.48it/s, Train Loss=0.6439, Val Loss=0.6038]"
      }
     },
     "d69f83f808e14ca1b292e42ee009be12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e1b7fbcea01a4f7980f047ea2e6f0379": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_80390db82ddc454d8b0dbb7bb722ce91",
       "max": 100.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_04757055ed7c44459f095aa7280a2ca3",
       "tabbable": null,
       "tooltip": null,
       "value": 100.0
      }
     },
     "f6d3ec44cc8b441398e9e22f0a8bc278": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
