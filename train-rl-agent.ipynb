{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "927791eb",
   "metadata": {
    "papermill": {
     "duration": 0.003443,
     "end_time": "2025-12-22T13:21:47.067864",
     "exception": false,
     "start_time": "2025-12-22T13:21:47.064421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# =============================================================================\n",
    "# REINFORCEMENT LEARNING AGENT TRAINING NOTEBOOK\n",
    "# =============================================================================\n",
    "## Purpose:\n",
    "    - Define the custom RL Environment (`SustainableAIAgentEnv`) with fail-safe reward mechanisms.\n",
    "    - Implement a Proximal Policy Optimization (PPO) agent with entropy regularization.\n",
    "    - Conduct a comparative benchmark against a Random Search strategy.\n",
    "    - Save the best-performing policy and metrics for final evaluation.\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa303e6",
   "metadata": {
    "papermill": {
     "duration": 0.002527,
     "end_time": "2025-12-22T13:21:47.073133",
     "exception": false,
     "start_time": "2025-12-22T13:21:47.070606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# === Clone Repository & Install Dependencies ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6ddaf92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T13:21:47.079920Z",
     "iopub.status.busy": "2025-12-22T13:21:47.079278Z",
     "iopub.status.idle": "2025-12-22T13:21:48.054195Z",
     "shell.execute_reply": "2025-12-22T13:21:48.053108Z"
    },
    "papermill": {
     "duration": 0.979799,
     "end_time": "2025-12-22T13:21:48.055544",
     "exception": false,
     "start_time": "2025-12-22T13:21:47.075745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Sustainable_AI_Agent_Project'...\r\n",
      "remote: Enumerating objects: 68, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (68/68), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (51/51), done.\u001b[K\r\n",
      "remote: Total 68 (delta 26), reused 54 (delta 15), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (68/68), 1.16 MiB | 15.23 MiB/s, done.\r\n",
      "Resolving deltas: 100% (26/26), done.\r\n",
      "/kaggle/working/Sustainable_AI_Agent_Project\n"
     ]
    }
   ],
   "source": [
    "# Use if run on Kaggle\n",
    "!rm -rf Sustainable_AI_Agent_Project\n",
    "!git clone https://github.com/trongjhuongwr/Sustainable_AI_Agent_Project.git\n",
    "%cd Sustainable_AI_Agent_Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afca6401",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T13:21:48.062978Z",
     "iopub.status.busy": "2025-12-22T13:21:48.062321Z",
     "iopub.status.idle": "2025-12-22T13:24:40.961073Z",
     "shell.execute_reply": "2025-12-22T13:24:40.960051Z"
    },
    "papermill": {
     "duration": 172.904447,
     "end_time": "2025-12-22T13:24:40.963124",
     "exception": false,
     "start_time": "2025-12-22T13:21:48.058677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m117.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m127.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m118.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.6/357.6 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.2/70.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "kaggle-environments 1.18.0 requires shimmy>=1.2.1, but you have shimmy 1.1.0 which is incompatible.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires ale-py>=0.10.1, but you have ale-py 0.8.1 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "tokenizers 0.21.2 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 1.0.0rc2 which is incompatible.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.5.1+cu121 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "google-genai 1.27.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.5.1+cu121 which is incompatible.\r\n",
      "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.27.2 which is incompatible.\r\n",
      "transformers 4.53.3 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.0rc2 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.4.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q --extra-index-url https://download.pytorch.org/whl/cu121 -r /kaggle/working/Sustainable_AI_Agent_Project/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9b07f4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T13:24:41.020513Z",
     "iopub.status.busy": "2025-12-22T13:24:41.019789Z",
     "iopub.status.idle": "2025-12-22T13:24:42.563511Z",
     "shell.execute_reply": "2025-12-22T13:24:42.562624Z"
    },
    "papermill": {
     "duration": 1.573152,
     "end_time": "2025-12-22T13:24:42.564700",
     "exception": false,
     "start_time": "2025-12-22T13:24:40.991548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torchvision 0.21.0+cu124\r\n",
      "Uninstalling torchvision-0.21.0+cu124:\r\n",
      "  Successfully uninstalled torchvision-0.21.0+cu124\r\n",
      "Torchvision uninstalled.\n"
     ]
    }
   ],
   "source": [
    "# Uninstall torchvision to prevent import conflicts with ptflops/pytorch\n",
    "!pip uninstall -y torchvision\n",
    "print(\"Torchvision uninstalled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77557c4",
   "metadata": {
    "papermill": {
     "duration": 0.026654,
     "end_time": "2025-12-22T13:24:42.619703",
     "exception": false,
     "start_time": "2025-12-22T13:24:42.593049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Import Libraries and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e4db64d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T13:24:42.675317Z",
     "iopub.status.busy": "2025-12-22T13:24:42.674574Z",
     "iopub.status.idle": "2025-12-22T13:24:58.747481Z",
     "shell.execute_reply": "2025-12-22T13:24:58.746392Z"
    },
    "papermill": {
     "duration": 16.102218,
     "end_time": "2025-12-22T13:24:58.748811",
     "exception": false,
     "start_time": "2025-12-22T13:24:42.646593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-22 13:24:48.063452: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1766409888.253697      20 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1766409888.305716      20 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "import json\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# Suppress specific warnings for cleaner output\n",
    "os.environ[\"GYM_DISABLE_WARNINGS\"] = \"true\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", module=\"gymnasium\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "logging.getLogger(\"gymnasium\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"stable_baselines3\").setLevel(logging.ERROR)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from sklearn.metrics import accuracy_score\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from codecarbon import EmissionsTracker\n",
    "from ptflops import get_model_complexity_info\n",
    "import torch_pruning as tp\n",
    "from tqdm.notebook import tqdm\n",
    "from builtins import print as builtin_print\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a01f80",
   "metadata": {
    "papermill": {
     "duration": 0.039658,
     "end_time": "2025-12-22T13:24:58.837193",
     "exception": false,
     "start_time": "2025-12-22T13:24:58.797535",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Configuration Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "340fccb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T13:24:58.892772Z",
     "iopub.status.busy": "2025-12-22T13:24:58.892235Z",
     "iopub.status.idle": "2025-12-22T13:24:58.954793Z",
     "shell.execute_reply": "2025-12-22T13:24:58.953852Z"
    },
    "papermill": {
     "duration": 0.091546,
     "end_time": "2025-12-22T13:24:58.955960",
     "exception": false,
     "start_time": "2025-12-22T13:24:58.864414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded. Using device: cuda\n",
      "Seed set to: 42\n",
      "Loading processed data from: /kaggle/input/baseline-model-saa/processed_data.pt\n",
      "Loading baseline model from: /kaggle/input/baseline-model-saa/baseline_model.pth\n",
      "Agent will be saved to: /kaggle/working/sustainable_ai_agent_ppo.zip\n"
     ]
    }
   ],
   "source": [
    "# Defines hyperparameters, file paths, and environment parameters used throughout the notebook.\n",
    "class Config:\n",
    "    # --- Input/Output Paths ---\n",
    "    PROCESSED_DATA_PATH = '/kaggle/input/baseline-model-saa/processed_data.pt'  # Input: Path to saved processed data tensors\n",
    "    BASELINE_MODEL_PATH = '/kaggle/input/baseline-model-saa/baseline_model.pth' # Input: Path to the trained baseline model state dictionary\n",
    "    AGENT_SAVE_PATH = \"/kaggle/working/sustainable_ai_agent_ppo.zip\"            # Output: Path to save/load the trained PPO agent\n",
    "    BEST_ACTION_SAVE_PATH = \"/kaggle/working/best_action.json\"                  # Output: Path to save information about the best discovered action\n",
    "    TENSORBOARD_LOG_PATH = \"/kaggle/working/ppo_tensorboard/\"                   # Output: Directory for TensorBoard logs\n",
    "\n",
    "    # --- Data Parameters (consistent with baseline training) ---\n",
    "    SEQUENCE_LENGTH = 30\n",
    "    INPUT_DIM = 4\n",
    "\n",
    "    # --- Model Architecture Parameters (must match baseline) ---\n",
    "    HIDDEN_DIM = 256\n",
    "    N_LAYERS = 2\n",
    "    OUTPUT_DIM = 1\n",
    "    DROPOUT = 0.2\n",
    "\n",
    "    # --- RL Agent Training Parameters ---\n",
    "    TOTAL_TIMESTEPS = 30000    # Total number of environment steps for training\n",
    "    TIMESTEPS_PER_CHUNK = 500  # Save agent state every N steps\n",
    "    SEED = 42                  # For reproducibility\n",
    "\n",
    "    # --- RL Environment Parameters (Reward shaping and constraints) ---\n",
    "    ACCURACY_PENALTY_THRESHOLD = 0.98   # Threshold below baseline accuracy triggering heavy penalty (e.g., 0.95 = 5% drop allowed)\n",
    "    ACC_REWARD_SCALE = 20.0             # Scaling factor for accuracy-based reward/penalty\n",
    "    FLOPS_REWARD_SCALE = 2.0            # Scaling factor for inference FLOPs reduction reward\n",
    "    PARAMS_REWARD_SCALE = 1.0           # Scaling factor for parameter reduction reward (training energy proxy)\n",
    "    INACTION_PENALTY = -1.0             # Penalty for choosing action 0 (no optimization)\n",
    "    ENV_ERROR_REWARD = -10.0            # Heavy penalty if an environment step fails (e.g., optimization error)\n",
    "\n",
    "    # --- Evaluation Parameters (within the environment) ---\n",
    "    EVAL_BATCH_SIZE = 64      # Batch size used for evaluation within the environment\n",
    "    CODECARBON_BATCHES = 10   # Number of batches used for CodeCarbon energy measurement during env init\n",
    "\n",
    "    # --- Computation Device ---\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(Config.SEED)\n",
    "\n",
    "print(f\"Configuration loaded. Using device: {Config.DEVICE}\")\n",
    "print(f\"Seed set to: {Config.SEED}\")\n",
    "print(f\"Loading processed data from: {Config.PROCESSED_DATA_PATH}\")\n",
    "print(f\"Loading baseline model from: {Config.BASELINE_MODEL_PATH}\")\n",
    "print(f\"Agent will be saved to: {Config.AGENT_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c838ce4f",
   "metadata": {
    "papermill": {
     "duration": 0.027804,
     "end_time": "2025-12-22T13:24:59.011240",
     "exception": false,
     "start_time": "2025-12-22T13:24:58.983436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Utility Functions and Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d0060b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T13:24:59.066340Z",
     "iopub.status.busy": "2025-12-22T13:24:59.065829Z",
     "iopub.status.idle": "2025-12-22T13:24:59.071387Z",
     "shell.execute_reply": "2025-12-22T13:24:59.070799Z"
    },
    "papermill": {
     "duration": 0.033796,
     "end_time": "2025-12-22T13:24:59.072400",
     "exception": false,
     "start_time": "2025-12-22T13:24:59.038604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"Returns the total number of trainable parameters.\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "class WeatherGRU(nn.Module):\n",
    "    \"\"\"\n",
    "    GRU Architecture (Must be identical to Baseline for state dict loading).\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(WeatherGRU, self).__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=config.INPUT_DIM,\n",
    "            hidden_size=config.HIDDEN_DIM,\n",
    "            num_layers=config.N_LAYERS,\n",
    "            batch_first=True,\n",
    "            dropout=config.DROPOUT if config.N_LAYERS > 1 else 0\n",
    "        )\n",
    "        self.fc = nn.Linear(config.HIDDEN_DIM, config.OUTPUT_DIM)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6799c537",
   "metadata": {
    "papermill": {
     "duration": 0.027491,
     "end_time": "2025-12-22T13:24:59.126517",
     "exception": false,
     "start_time": "2025-12-22T13:24:59.099026",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Optimization Primitives (Pruning & Quantization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d39c015f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T13:24:59.180641Z",
     "iopub.status.busy": "2025-12-22T13:24:59.180429Z",
     "iopub.status.idle": "2025-12-22T13:24:59.186036Z",
     "shell.execute_reply": "2025-12-22T13:24:59.185357Z"
    },
    "papermill": {
     "duration": 0.03402,
     "end_time": "2025-12-22T13:24:59.187081",
     "exception": false,
     "start_time": "2025-12-22T13:24:59.153061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    Counts effective (non-zero) parameters. \n",
    "    Crucial for rewarding unstructured pruning (sparsity).\n",
    "    \"\"\"\n",
    "    total_params = 0\n",
    "    for p in model.parameters():\n",
    "        if p.requires_grad:\n",
    "            # Only count non-zero weights (Effective Sparsity)\n",
    "            total_params += torch.count_nonzero(p).item()\n",
    "    return total_params\n",
    "\n",
    "def apply_pruning(model, amount):\n",
    "    \"\"\"\n",
    "    Applies Unstructured L1 Pruning to the Linear layer weights.\n",
    "    This creates sparsity (zeros) without changing tensor shapes, preventing crashes.\n",
    "    \"\"\"\n",
    "    if amount <= 0: return model\n",
    "    \n",
    "    model_copy = copy.deepcopy(model)\n",
    "    for name, module in model_copy.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            # Prune 'amount' % of weights with lowest L1 magnitude\n",
    "            prune.l1_unstructured(module, name='weight', amount=amount)\n",
    "            # Make pruning permanent (remove mask) for cleaner export\n",
    "            prune.remove(module, 'weight')\n",
    "    return model_copy\n",
    "\n",
    "def apply_quantization(model):\n",
    "    \"\"\"\n",
    "    Applies dynamic quantization (INT8) to reduce model size and theoretical latency.\n",
    "    \"\"\"\n",
    "    model_copy = copy.deepcopy(model)\n",
    "    model_copy.to('cpu')\n",
    "    model_copy.eval()\n",
    "    # Quantize Linear and GRU layers\n",
    "    quantized_model = torch.quantization.quantize_dynamic(\n",
    "        model_copy, {nn.Linear, nn.GRU}, dtype=torch.qint8\n",
    "    )\n",
    "    return quantized_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7909081",
   "metadata": {
    "papermill": {
     "duration": 0.02669,
     "end_time": "2025-12-22T13:24:59.240306",
     "exception": false,
     "start_time": "2025-12-22T13:24:59.213616",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Custom RL Environment with Fail-Safe Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c169dbbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T13:24:59.294915Z",
     "iopub.status.busy": "2025-12-22T13:24:59.294683Z",
     "iopub.status.idle": "2025-12-22T13:24:59.306686Z",
     "shell.execute_reply": "2025-12-22T13:24:59.306144Z"
    },
    "papermill": {
     "duration": 0.040982,
     "end_time": "2025-12-22T13:24:59.307689",
     "exception": false,
     "start_time": "2025-12-22T13:24:59.266707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SustainableAIAgentEnv(gym.Env):\n",
    "    def __init__(self, baseline_model, val_loader, config):\n",
    "        super(SustainableAIAgentEnv, self).__init__()\n",
    "        self.baseline_model = baseline_model\n",
    "        self.val_loader = val_loader\n",
    "        self.config = config\n",
    "        \n",
    "        # Calculate Baseline Metrics using the FIXED count_parameters\n",
    "        # We assume baseline is unpruned and FP32\n",
    "        self.baseline_metrics = self._evaluate_performance(self.baseline_model)\n",
    "        # Force baseline FLOPs to a fixed high value if not set, to ensure relative reduction works\n",
    "        if self.baseline_metrics['flops'] < 1000: self.baseline_metrics['flops'] = 1e6 \n",
    "            \n",
    "        print(f\"Baseline Metrics: {self.baseline_metrics}\")\n",
    "        \n",
    "        self.pruning_levels = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "        self.action_space = spaces.Discrete(len(self.pruning_levels) * 2)\n",
    "        self.observation_space = spaces.Box(low=-1.0, high=1.0, shape=(4,), dtype=np.float32)\n",
    "        \n",
    "    def _evaluate_performance(self, model):\n",
    "        model.eval()\n",
    "\n",
    "        is_quantized = any(\"quantized\" in str(type(m)).lower() for m in model.modules())\n",
    "        \n",
    "        if is_quantized:\n",
    "            device = torch.device(\"cpu\")\n",
    "        else:\n",
    "            device = torch.device(self.config.DEVICE)\n",
    "            \n",
    "        model.to(device)\n",
    "        \n",
    "        # 1. Accuracy\n",
    "        y_true, y_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for X, y in self.val_loader:\n",
    "                X = X.to(device)\n",
    "                preds = (model(X) > 0.5).float()\n",
    "                y_true.extend(y.cpu().numpy())\n",
    "                y_pred.extend(preds.cpu().numpy())\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        \n",
    "        # 2. Parameters (Non-zero count)\n",
    "        params = count_parameters(model)\n",
    "        \n",
    "        # 3. Robust FLOPs/Energy Proxy\n",
    "        baseline_p = self.baseline_metrics['params'] if hasattr(self, 'baseline_metrics') else params\n",
    "        if baseline_p == 0: baseline_p = 1\n",
    "        \n",
    "        param_ratio = params / baseline_p\n",
    "        \n",
    "        # Check Quantization\n",
    "        # PyTorch Dynamic Quantization swaps nn.Linear with nn.quantized.dynamic.Linear\n",
    "        is_quantized = any(\"quantized\" in str(type(m)).lower() for m in model.modules())\n",
    "        quant_factor = 0.25 if is_quantized else 1.0\n",
    "        \n",
    "        # Baseline FLOPs\n",
    "        baseline_f = self.baseline_metrics['flops'] if hasattr(self, 'baseline_metrics') else 1e6\n",
    "        \n",
    "        flops = baseline_f * param_ratio * quant_factor\n",
    "        return {\"accuracy\": accuracy, \"params\": params, \"flops\": flops}\n",
    "\n",
    "    def step(self, action):\n",
    "        pruning_idx = action % len(self.pruning_levels)\n",
    "        quantization_idx = action // len(self.pruning_levels)\n",
    "        \n",
    "        pruning_rate = self.pruning_levels[pruning_idx]\n",
    "        use_quantization = bool(quantization_idx)\n",
    "        \n",
    "        current_model = copy.deepcopy(self.baseline_model)\n",
    "        # Apply Fixed Pruning\n",
    "        current_model = apply_pruning(current_model, pruning_rate)\n",
    "        # Apply Quantization\n",
    "        if use_quantization:\n",
    "            current_model = apply_quantization(current_model)\n",
    "            \n",
    "        metrics = self._evaluate_performance(current_model)\n",
    "        \n",
    "        # Rewards\n",
    "        acc_drop = metrics['accuracy'] - self.baseline_metrics['accuracy']\n",
    "        flops_reduction = 1.0 - (metrics['flops'] / self.baseline_metrics['flops'])\n",
    "        params_reduction = 1.0 - (metrics['params'] / self.baseline_metrics['params'])\n",
    "        \n",
    "        if metrics['accuracy'] < (self.baseline_metrics['accuracy'] * self.config.ACCURACY_PENALTY_THRESHOLD):\n",
    "            acc_reward = -10.0\n",
    "        else:\n",
    "            acc_reward = acc_drop * self.config.ACC_REWARD_SCALE\n",
    "            \n",
    "        eff_reward = (flops_reduction * self.config.FLOPS_REWARD_SCALE) + \\\n",
    "                     (params_reduction * self.config.PARAMS_REWARD_SCALE)\n",
    "        \n",
    "        total_reward = acc_reward + eff_reward\n",
    "        \n",
    "        obs = np.array([metrics['accuracy'], acc_drop, params_reduction, flops_reduction], dtype=np.float32)\n",
    "        info = {\n",
    "            \"pruning_rate\": pruning_rate, \n",
    "            \"quantization\": use_quantization, \n",
    "            \"accuracy\": metrics['accuracy'],\n",
    "            \"reward\": total_reward\n",
    "        }\n",
    "        \n",
    "        return obs, total_reward, True, False, info\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        super().reset(seed=seed)\n",
    "        obs = np.array([self.baseline_metrics['accuracy'], 0.0, 0.0, 0.0], dtype=np.float32)\n",
    "        return obs, {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e520474",
   "metadata": {
    "papermill": {
     "duration": 0.025803,
     "end_time": "2025-12-22T13:24:59.360643",
     "exception": false,
     "start_time": "2025-12-22T13:24:59.334840",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Main Execution Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0de59666",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T13:24:59.413708Z",
     "iopub.status.busy": "2025-12-22T13:24:59.413454Z",
     "iopub.status.idle": "2025-12-22T13:51:13.816868Z",
     "shell.execute_reply": "2025-12-22T13:51:13.816142Z"
    },
    "papermill": {
     "duration": 1574.431505,
     "end_time": "2025-12-22T13:51:13.818058",
     "exception": false,
     "start_time": "2025-12-22T13:24:59.386553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline artifacts loaded successfully.\n",
      "Baseline Metrics: {'accuracy': 0.6608695652173913, 'params': 596225, 'flops': 1000000.0}\n",
      "\n",
      "--- Starting PPO Agent Training ---\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | 1.48     |\n",
      "| time/              |          |\n",
      "|    fps             | 32       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 63       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 1.99        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029892873 |\n",
      "|    clip_fraction        | 0.864       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.74       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.863       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.18       |\n",
      "|    value_loss           | 2.42        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 2.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 230         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054016277 |\n",
      "|    clip_fraction        | 0.953       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.59       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.845       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.186      |\n",
      "|    value_loss           | 2.17        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 2.84      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 23        |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 342       |\n",
      "|    total_timesteps      | 8192      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1710625 |\n",
      "|    clip_fraction        | 0.888     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.32     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.561     |\n",
      "|    n_updates            | 30        |\n",
      "|    policy_gradient_loss | -0.159    |\n",
      "|    value_loss           | 1.61      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 3          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 22         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 456        |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07584684 |\n",
      "|    clip_fraction        | 0.238      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.15      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.192      |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0615    |\n",
      "|    value_loss           | 0.49       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 3.11      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 22        |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 555       |\n",
      "|    total_timesteps      | 12288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0940599 |\n",
      "|    clip_fraction        | 0.869     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.94     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.00657  |\n",
      "|    n_updates            | 50        |\n",
      "|    policy_gradient_loss | -0.101    |\n",
      "|    value_loss           | 0.0866    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 3.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 670         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049292743 |\n",
      "|    clip_fraction        | 0.942       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.196      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.152      |\n",
      "|    value_loss           | 0.073       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 3.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 787         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031271726 |\n",
      "|    clip_fraction        | 0.952       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.192      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.176      |\n",
      "|    value_loss           | 0.0601      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 3.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 902         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033947222 |\n",
      "|    clip_fraction        | 0.928       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0193     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.186      |\n",
      "|    value_loss           | 0.0344      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 3.31       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 20         |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 1019       |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07287234 |\n",
      "|    clip_fraction        | 0.926      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.635     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.183     |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.171     |\n",
      "|    value_loss           | 0.0359     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 3.34      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 19        |\n",
      "|    iterations           | 11        |\n",
      "|    time_elapsed         | 1134      |\n",
      "|    total_timesteps      | 22528     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3278908 |\n",
      "|    clip_fraction        | 0.132     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.119    |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.111    |\n",
      "|    n_updates            | 100       |\n",
      "|    policy_gradient_loss | -0.112    |\n",
      "|    value_loss           | 0.0198    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | 3.34         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 1244         |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006975316 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0249      |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000243    |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00675     |\n",
      "|    value_loss           | 0.000648     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | 3.35         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 1356         |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001696294 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0187      |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0239      |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    value_loss           | 0.000296     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 3.35        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 1466        |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 9.20303e-05 |\n",
      "|    clip_fraction        | 0.00132     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0151     |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000156   |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00213    |\n",
      "|    value_loss           | 0.000179    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1            |\n",
      "|    ep_rew_mean          | 3.34         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 1568         |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003980901 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0105      |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000105    |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.005       |\n",
      "|    value_loss           | 0.000418     |\n",
      "------------------------------------------\n",
      "PPO Training Completed.\n",
      "\n",
      "--- Running Random Search Benchmark ---\n",
      "Random Search Best Reward: 3.3478\n",
      "Random Search Strategy: {'pruning_rate': 0.7, 'quantization': True, 'accuracy': 0.6782608695652174, 'reward': 3.347826086956522}\n",
      "\n",
      "--- Comparison ---\n",
      "Agent Best Reward: 3.347826086956522\n",
      "Agent Strategy: Pruning=0.7, Quant=True\n",
      "Best action saved to /kaggle/working/best_action.json\n"
     ]
    }
   ],
   "source": [
    "# A. Load Data & Model\n",
    "try:\n",
    "    processed_data = torch.load(Config.PROCESSED_DATA_PATH)\n",
    "    # Use Validation set for RL Agent feedback (Test set is for final eval only)\n",
    "    val_dataset = TensorDataset(processed_data['X_val'], processed_data['y_val'])\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False) # Large batch for faster step\n",
    "\n",
    "    baseline_model = WeatherGRU(Config)\n",
    "    baseline_model.load_state_dict(torch.load(Config.BASELINE_MODEL_PATH))\n",
    "    print(\"Baseline artifacts loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}. Please check Config paths.\")\n",
    "\n",
    "# B. Initialize Environment\n",
    "env = SustainableAIAgentEnv(baseline_model, val_loader, Config)\n",
    "\n",
    "# C. Train PPO Agent\n",
    "print(\"\\n--- Starting PPO Agent Training ---\")\n",
    "\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freq=5000,\n",
    "    save_path='/kaggle/working/checkpoints/',\n",
    "    name_prefix='ppo_agent_sustainable'\n",
    ")\n",
    "\n",
    "# ent_coef=0.01 encourages exploration (prevents getting stuck in local optima)\n",
    "agent = PPO(\"MlpPolicy\", env, verbose=1, seed=Config.SEED, ent_coef=0.01, device=Config.DEVICE)\n",
    "agent.learn(total_timesteps=Config.TOTAL_TIMESTEPS, callback=checkpoint_callback)\n",
    "agent.save(Config.AGENT_SAVE_PATH)\n",
    "print(\"PPO Training Completed.\")\n",
    "\n",
    "# D. Benchmark: Random Search (Requirement: Comparison with other methods)\n",
    "print(\"\\n--- Running Random Search Benchmark ---\")\n",
    "best_random_reward = -float('inf')\n",
    "best_random_action = None\n",
    "\n",
    "for _ in range(50): # 50 Random Trials\n",
    "    action = env.action_space.sample()\n",
    "    _, reward, _, _, info = env.step(action)\n",
    "    \n",
    "    if reward > best_random_reward:\n",
    "        best_random_reward = reward\n",
    "        best_random_action = info\n",
    "\n",
    "print(f\"Random Search Best Reward: {best_random_reward:.4f}\")\n",
    "print(f\"Random Search Strategy: {best_random_action}\")\n",
    "\n",
    "# E. Save Best Agent Action\n",
    "# Extract best action from PPO (Predict on initial state)\n",
    "obs, _ = env.reset()\n",
    "action, _ = agent.predict(obs, deterministic=True)\n",
    "_, _, _, _, best_agent_info = env.step(action)\n",
    "\n",
    "print(\"\\n--- Comparison ---\")\n",
    "print(f\"Agent Best Reward: {best_agent_info['reward'] if 'reward' in best_agent_info else 'N/A'}\")\n",
    "print(f\"Agent Strategy: Pruning={best_agent_info['pruning_rate']}, Quant={best_agent_info['quantization']}\")\n",
    "\n",
    "# Save for evaluation notebook\n",
    "with open(Config.BEST_ACTION_SAVE_PATH, 'w') as f:\n",
    "    json.dump({\n",
    "        \"action_code\": int(action),\n",
    "        \"pruning_rate\": float(best_agent_info['pruning_rate']),\n",
    "        \"quantization\": bool(best_agent_info['quantization'])\n",
    "    }, f)\n",
    "print(f\"Best action saved to {Config.BEST_ACTION_SAVE_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1868601,
     "sourceId": 3051857,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8585703,
     "sourceId": 14254451,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1773.752309,
   "end_time": "2025-12-22T13:51:16.955711",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-22T13:21:43.203402",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
